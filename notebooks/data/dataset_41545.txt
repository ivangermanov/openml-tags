The Emotions dataset is a multi-label audio dataset consisting of 593 musical files, each of which can be labeled with one or more of six clustered emotional labels: Amazed-Surprised, Happy-Pleased, Relaxing-Calm, Quiet-Still, Sad-Lonely, and Angry-Aggressive.

This dataset contains seventy-two predictors, including various acoustic features such as Centroid, Rolloff, Flux, and Mel-Frequency Cepstral Coefficients (MFCCs). These features are calculated using different statistical measures, including mean and standard deviation, to capture various aspects of the audio signals.

The Emotions dataset provides a rich platform for exploring the complex relationships between music and emotions, enabling researchers to develop and evaluate machine learning models that can accurately predict the emotional labels associated with different pieces of music.

Keywords: Emotions dataset, multi-label classification, audio analysis, music emotion recognition, acoustic features.