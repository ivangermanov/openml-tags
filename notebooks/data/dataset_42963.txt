**SGEMM GPU Kernel Performance Dataset**
**Tags:**

This dataset measures the running time of a matrix-matrix product A times B equals C, where all matrices have a size of two thousand forty-eight by two thousand forty-eight, using a parameterizable SGEMM GPU kernel with a large number of possible parameter combinations. For each tested combination, four runs were performed and their results are reported as the four last columns. All times are measured in milliseconds. There are fourteen parameters, the first ten of which are ordinal and can only take up to four different powers of two values, and the four last variables are binary. Out of a total number of parameter combinations, only a subset are feasible due to various kernel constraints. This dataset contains the results for all these feasible combinations.

The experiment was run on a desktop workstation running Ubuntu Linux with an Intel Core i5 processor, sixteen gigabytes of RAM, and an NVIDIA GeForce GTX six eighty GPU. We use the 'gemm fast' kernel from the automatic OpenCL kernel tuning library 'CLTune'.

Note that for this kind of dataset, it is usually better to work with the logarithm of the running times.

**Attribute Information**

Independent variables include per-matrix two-dimensional tiling at workgroup level, inner dimension of two-dimensional tiling at workgroup level, local workgroup size, local memory shape, kernel loop unrolling factor, per-matrix vector widths for loading and storing, enable stride for accessing off-chip memory within a single thread, and per-matrix manual caching of the two-dimensional workgroup tile.

Output includes performance times in milliseconds for four independent runs using the same parameters.

**Keywords:** SGEMM, GPU kernel, matrix-matrix product, performance optimization, OpenCL, kernel tuning.