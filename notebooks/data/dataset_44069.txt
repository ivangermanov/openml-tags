Name: SGEMM GPU Kernel Performance
Tags: Dataset used in the tabular data benchmark, transformed in the same way, regression on categorical and numerical features

This dataset measures the running time of a matrix-matrix product using a parameterizable Single Precision General Matrix Multiply GPU kernel with a large number of possible parameter combinations. For each tested combination, multiple runs were performed and their results are reported. All times are measured in milliseconds.

The dataset contains fourteen parameters, with the first ten being ordinal and able to take on up to four different powers of two values, and the last four being binary. Out of a total of possible parameter combinations, only a subset are feasible due to various kernel constraints. This dataset contains the results for all these feasible combinations.

The experiment was run on a desktop workstation with a specific configuration, including an Intel Core i5 processor, sixteen gigabytes of RAM, and a NVIDIA GeForce GTX 680 GPU. The gemm fast kernel from the automatic OpenCL kernel tuning library CLTune was used.

It is usually better to work with the logarithm of the running times for this type of dataset.

The independent variables include per-matrix two-dimensional tiling at the workgroup level, the inner dimension of two-dimensional tiling at the workgroup level, local workgroup size, local memory shape, kernel loop unrolling factor, per-matrix vector widths for loading and storing, and enable stride for accessing off-chip memory within a single thread. The output variables include performance times in milliseconds for multiple independent runs using the same parameters.

This dataset is related to studies on global sensitivity analysis.

The original data was obtained from the UCI Machine Learning repository.

Please cite the relevant papers.

Features: kernel loop unrolling factor, enable stride for accessing off-chip memory, manual caching of the two-dimensional workgroup tile, performance times

Keywords: matrix-matrix product, GPU kernel, parameter tuning, performance optimization, global sensitivity analysis