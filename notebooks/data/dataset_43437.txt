Gender Recognition by Voice and Speech Analysis

This database was created to identify a voice as male or female, based upon acoustic properties of the voice and speech. The dataset consists of recorded voice samples, collected from male and female speakers. The voice samples are pre-processed by acoustic analysis, with an analyzed frequency range of human vocal range.

The dataset includes the following acoustic properties of each voice: mean frequency, standard deviation of frequency, median frequency, first quantile, third quantile, interquantile range, skewness, kurtosis, spectral entropy, spectral flatness, mode frequency, frequency centroid, peak frequency, average of fundamental frequency, minimum fundamental frequency, maximum fundamental frequency, average of dominant frequency, minimum of dominant frequency, maximum of dominant frequency, range of dominant frequency, and modulation index.

The accuracy of the baseline model, which always predicts male, is fifty percent. The logistic regression model achieves an accuracy of ninety-seven percent, while the CART model achieves an accuracy of ninety-six percent. The random forest model achieves an accuracy of one hundred percent, as does the SVM model and the XGBoost model.

Research questions include what other features differ between male and female voices, can we find a difference in resonance between male and female voices, and can we identify falsetto from regular voices. An original analysis of the dataset can be found in the article "Identifying the Gender of a Voice using Machine Learning". According to a CART model, it appears that looking at the mean fundamental frequency might be enough to accurately classify a voice. However, some male voices use a higher frequency, even though their resonance differs from female voices, and may be incorrectly classified as female. To the human ear, there is apparently more than simple frequency that determines a voice's gender.

The CART diagram shows that mean fundamental frequency appears to be an indicator of voice gender, with a threshold separating male from female classifications.

The dataset is related to other speech databases, including the Harvard-Haskins Database of Regularly-Timed Speech, the Telecommunications Signal Processing Laboratory Speech Database at McGill University, the VoxForge Speech Corpus, and the Festvox CMU_ARCTIC Speech Database at Carnegie Mellon University.

Keywords: voice gender recognition, speech analysis, acoustic properties, machine learning, fundamental frequency, resonance, falsetto.