Software to detect network intrusions protects a computer network from unauthorized users, including perhaps insiders. The intrusion detector learning task is to build a predictive model capable of distinguishing between bad connections, called intrusions or attacks, and good normal connections.

The 1998 DARPA Intrusion Detection Evaluation Program was prepared and managed by MIT Lincoln Labs. The objective was to survey and evaluate research in intrusion detection. A standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment, was provided. The 1999 KDD intrusion detection contest uses a version of this dataset.

Lincoln Labs set up an environment to acquire raw TCP dump data for a local area network simulating a typical US Air Force local area network. They operated the local area network as if it were a true Air Force environment, but peppered it with multiple attacks. The raw training data was processed into connection records. Similarly, the test data yielded connection records. A connection is a sequence of TCP packets starting and ending at some well-defined times, between which data flows to and from a source IP address to a target IP address under some well-defined protocol. Each connection is labeled as either normal, or as an attack, with exactly one specific attack type. Each connection record consists of about one hundred bytes.

Attacks fall into four main categories: Denial of Service, unauthorized access from a remote machine, unauthorized access to local superuser privileges, and surveillance and other probing. It is important to note that the test data is not from the same probability distribution as the training data, and it includes specific attack types not in the training data. This makes the task more realistic. Some intrusion experts believe that most novel attacks are variants of known attacks and the signature of known attacks can be sufficient to catch novel variants.

Derived Features help in distinguishing normal connections from attacks. There are several categories of Derived Features. The Same Host features examine only the connections in the past two seconds that have the same destination host as the current connection, and calculate statistics related to protocol behavior, service, etc. The Similar Same Service features examine only the connections in the past two seconds that have the same service as the current connection. Same Host and Same Service features are together called Time-Based Traffic Features of the connection records. Some Probing attacks scan the hosts or ports using a much larger time interval than two seconds, for example once per minute. Therefore, connection records were also sorted by destination host, and features were constructed using a window of one hundred connections to the same host instead of a time window. This yields a set of so-called Host-Based Traffic Features.

Unlike most of the Denial of Service and Probing attacks, there appear to be no sequential patterns that are frequent in records of Unauthorized Access from Remote Machine and Unauthorized Access to Local Superuser Privileges attacks. This is because the Denial of Service and Probing attacks involve many connections to some host(s) in a very short period of time, but the Unauthorized Access from Remote Machine and Unauthorized Access to Local Superuser Privileges attacks are embedded in the data portions of packets, and normally involve only a single connection. Useful algorithms for mining the unstructured data portions of packets automatically are an open research question.

A complete listing of the set of features defined for the connection records is given below:

Basic Features of Individual TCP Connections:

* Connection Duration: length of the connection
* Protocol Type: type of the protocol
* Service: network service on the destination
* Source Bytes: number of data bytes from source to destination
* Destination Bytes: number of data bytes from destination to source
* Flag: normal or error status of the connection
* Land: one if connection is from/to the same host/port; zero otherwise
* Wrong Fragment: number of wrong fragments
* Urgent: number of urgent packets

Content Features Within a Connection Suggested by Domain Knowledge:

* Hot: number of hot indicators
* Number of Failed Logins: number of failed login attempts
* Logged In: one if successfully logged in; zero otherwise
* Number of Compromised: number of compromised conditions
* Root Shell: one if root shell is obtained; zero otherwise
* SU Attempted: one if SU root command attempted; zero otherwise
* Number of Root: number of root accesses
* Number of File Creations: number of file creation operations
* Number of Shells: number of shell prompts
* Number of Access Files: number of operations on access control files
* Number of Outbound Commands: number of outbound commands in an FTP session
* Is Hot Login: one if the login belongs to the hot list; zero otherwise
* Is Guest Login: one if the login is a guest login; zero otherwise

Traffic Features Computed Using a Two-Second Time Window:

* Count: number of connections to the same host as the current connection in the past two seconds
* Same Server Rate: percentage of connections to the same service
* Different Server Rate: percentage of connections to different services
* Server Count: number of connections to the same service as the current connection in the past two seconds
* Server Same Error Rate: percentage of connections that have SYN errors
* Server Different Error Rate: percentage of connections that have REJ errors
* Server Different Host Rate: percentage of connections to different hosts

Keywords: Network Intrusions, Machine Learning, Computer Networks, Cybersecurity, Data Mining, Traffic Analysis, Feature Extraction