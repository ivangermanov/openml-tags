This database, known as the FEER Dataset, contains six basic emotions: happiness, surprise, anger, fear, disgust, and sadness. The data is normalized and collected from undergraduate university students, with a total of eighty-five participants, fifty-five male and thirty female, aged between twenty and twenty-seven years, with a mean age of twenty-four point five years. The data, which contains noises and other movement artifacts, is removed from the raw data.

A built-in FaceTime HD camera in Apple Mac Pro, with a resolution of two thousand five hundred sixty by sixteen hundred at two hundred twenty-seven pixels per inch, is used to collect the facial images in a controlled environment, with a room temperature of twenty-five degrees Celsius and fifty Lux lighting intensity, at thirty frames per second. All the subjects are seated comfortably in a chair in front of the camera, and the distance between the subject's face to the camera is zero point nine five meters.

A computerized PowerPoint slide is used to instruct the subjects to express the facial emotional expression by looking into the International Affective Picture System images of six different emotions. The data file contains eleven columns, ten columns for ten markers and the last column represents the label of emotion. Each emotion has ten trials, and each trial has a duration of six seconds. In between the emotional expressions, ten seconds of break is given to the subjects to feel calm by showing natural scenes. The PowerPoint show starts with a set of instructions at the beginning of the experiment, with a duration of ten seconds.

The computing system continuously records the marker positions and saves them in comma-separated values format for further processing. More information about the reproduction of data analysis could be found from the citations.

Keywords: facial emotion recognition, emotional expressions, International Affective Picture System, facial images, controlled environment, computerized PowerPoint slide.