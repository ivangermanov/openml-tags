The MoCap Hand Postures dataset is a collection of data obtained using a Vicon motion capture camera system to record twelve users performing five distinct hand postures while wearing a left-handed glove with markers attached to it. A rigid pattern of markers on the back of the glove was utilized to establish a local coordinate system for the hand, and eleven additional markers were attached to the thumb and fingers of the glove.

Three markers were attached to the thumb, with one positioned above the thumbnail and the other two on the knuckles. Two markers were attached to each finger, with one situated above the fingernail and the other on the joint between the proximal and middle phalanx. The eleven markers not part of the rigid pattern were unlabeled, and their positions were not explicitly tracked. Consequently, there is no a priori correspondence between the markers of two given records.

In addition, due to the resolution of the capture volume and self-occlusion caused by the orientation and configuration of the hand and fingers, many records contain missing markers. Extraneous markers were also possible due to artifacts in the Vicon software's marker reconstruction and recording process, as well as other objects present in the capture volume. As a result, the number of visible markers in a record varied significantly.

The data presented here is already partially preprocessed. Initially, all markers were transformed to the local coordinate system of the record containing them. Subsequently, each transformed marker with a norm greater than a certain threshold was pruned. Finally, any record that contained fewer than three markers was removed. The processed data has at most twelve markers per record and at least three.

Due to the manner in which the data was captured, it is likely that for a given record and user, there exists a near-duplicate record originating from the same user. Therefore, it is recommended to evaluate classification algorithms on a leave-one-user-out basis, where each user is iteratively left out from training and used as a test set. This approach allows testing of the generalization of the algorithm to new users. A user attribute is provided to accommodate this strategy.

This dataset may be utilized for various tasks, the most obvious being posture recognition through classification. Additionally, one may attempt user identification. Alternatively, one may perform clustering, either constrained or unconstrained, to discover marker distributions, either as an attempt to predict marker identities or obtain statistical descriptions and visualizations of the postures.

Data is provided as a comma-separated values file. A header furnishes the name of each attribute. An initial dummy record composed entirely of zeros should be disregarded. A question mark is employed to indicate a missing value. A record corresponds to a single instant or frame as recorded by the camera system.

Class refers to the class identity of the given record, ranging from one to five, with one representing fist with thumb out, two representing stop or hand flat, three representing point one or pointing with the pointer finger, four representing point two or pointing with the pointer and middle fingers, and five representing grab or fingers curled as if to grasp.

User refers to the identity of the user who contributed the record, serving solely as an identifier. Xi, Yi, and Zi represent the x, y, and z coordinates of the ith unlabeled marker position, respectively, with i ranging from zero to eleven. Each record is a set, and the ith marker of a given record does not necessarily correspond to the ith marker of a different record. It is permissible to randomly permute the visible markers of a given record without altering the set represented by the record. For the sake of convenience, all visible markers of a given record are assigned a lower index than any missing markers.

Keywords: motion capture, hand postures, machine learning, classification, clustering, user identification.