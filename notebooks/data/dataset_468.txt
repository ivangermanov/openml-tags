The Friedman Datasets are eighty artificially generated datasets originating from stochastic gradient boosting research. The dataset names are coded according to their characteristics, specifically the degree of colinearity, sample size, and number of features.

These datasets are based on the Friedman function, which includes both linear and nonlinear relationships between inputs and outputs, with a normalized noise term added to the output. This function provides a comprehensive testing ground for various algorithms, allowing researchers to evaluate their performance under different conditions.

To generate these datasets, the original Friedman function was modified to include additional features that are not related to the output. This was done to test the algorithms' ability to ignore irrelevant information. Furthermore, the datasets were designed to exhibit varying degrees of colinearity among the features, ranging from zero to four. This allows researchers to assess how well algorithms can handle correlated inputs.

The resulting datasets have varying numbers of features, including five, ten, twenty-five, fifty, and one hundred. Only the first five features are actually related to the output, while the remaining ones are randomly generated. Similarly, the datasets contain different sample sizes, specifically one hundred, two hundred and fifty, five hundred, and one thousand.

In total, eighty unique datasets were generated by combining these different parameters. Each dataset has a distinct set of characteristics, providing a rich environment for evaluating and comparing machine learning algorithms.

Keywords: Friedman Datasets, Artificial Data Generation, Stochastic Gradient Boosting, Colinearity, Feature Selection, Machine Learning Evaluation.