{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:07:45.918106Z",
     "start_time": "2024-03-11T10:07:41.305615Z"
    }
   },
   "outputs": [],
   "source": [
    "import openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/69z7wmcn5xx7cb7wc_xvd8fw0000gn/T/ipykernel_19706/3289773090.py:1: FutureWarning: Support for `output_format` of 'dict' will be removed in 0.15 and pandas dataframes will be returned instead. To ensure your code will continue to work, use `output_format`='dataframe'.\n",
      "  datasets = openml.datasets.list_datasets()\n"
     ]
    }
   ],
   "source": [
    "datasets = openml.datasets.list_datasets()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:07:47.219927Z",
     "start_time": "2024-03-11T10:07:45.918090Z"
    }
   },
   "id": "bcbfbd068d15e4df"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/69z7wmcn5xx7cb7wc_xvd8fw0000gn/T/ipykernel_19706/1330030242.py:1: FutureWarning: Support for `output_format` of 'dict' will be removed in 0.15 and pandas dataframes will be returned instead. To ensure your code will continue to work, use `output_format`='dataframe'.\n",
      "  openml.datasets.list_datasets()[531]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'did': 531,\n 'name': 'boston',\n 'version': 1,\n 'uploader': '2',\n 'status': 'active',\n 'format': 'ARFF',\n 'MaxNominalAttDistinctValues': 9.0,\n 'NumberOfClasses': 0.0,\n 'NumberOfFeatures': 14.0,\n 'NumberOfInstances': 506.0,\n 'NumberOfInstancesWithMissingValues': 0.0,\n 'NumberOfMissingValues': 0.0,\n 'NumberOfNumericFeatures': 12.0,\n 'NumberOfSymbolicFeatures': 2.0}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openml.datasets.list_datasets()[531]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:07:48.488338Z",
     "start_time": "2024-03-11T10:07:47.220738Z"
    }
   },
   "id": "1d620ef22ba54e79"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "5437"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_ids is ordered_dict, map to variable with only ids\n",
    "ids = list(datasets.keys())\n",
    "len(ids)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:07:48.495450Z",
     "start_time": "2024-03-11T10:07:48.489877Z"
    }
   },
   "id": "273640f993c25271"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# remove 4537, 4546, 4562, because it is not a dataset\n",
    "ids.remove(4537)\n",
    "ids.remove(4546)\n",
    "ids.remove(4562)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:07:48.496224Z",
     "start_time": "2024-03-11T10:07:48.493411Z"
    }
   },
   "id": "cde5f5dce80b18b2"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivang/miniconda3/envs/openml-tags/lib/python3.12/site-packages/openml/datasets/functions.py:447: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  get_dataset(dataset_id, download_data, download_qualities=download_qualities),\n"
     ]
    },
    {
     "data": {
      "text/plain": "5434"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = openml.datasets.get_datasets(ids, download_data=False, download_qualities=False)\n",
    "len(datasets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:07:57.177698Z",
     "start_time": "2024-03-11T10:07:48.496339Z"
    }
   },
   "id": "3537414e2037f583"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "5169"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all datasets with non-empty description\n",
    "datasets = [dataset for dataset in datasets if dataset.description]\n",
    "len(datasets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:07:57.229692Z",
     "start_time": "2024-03-11T10:07:57.217017Z"
    }
   },
   "id": "a763059765a7365c"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "4665"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove datasets with description length < 100\n",
    "datasets = [dataset for dataset in datasets if len(dataset.description) >= 100]\n",
    "len(datasets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:07:57.274890Z",
     "start_time": "2024-03-11T10:07:57.267784Z"
    }
   },
   "id": "bf044b14b71f54fb"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "OpenML Dataset\n==============\nName.........: anneal\nVersion......: 1\nFormat.......: ARFF\nUpload Date..: 2014-04-06 23:19:24\nLicence......: Public\nDownload URL.: https://api.openml.org/data/v1/download/1666876/anneal.arff\nOpenML URL...: https://www.openml.org/d/2\n# of features: 39"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:07:57.275757Z",
     "start_time": "2024-03-11T10:07:57.272733Z"
    }
   },
   "id": "99867c78ed26b528"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "3743"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [dataset.description for dataset in datasets]\n",
    "\n",
    "# remove all datasets with identical descriptions\n",
    "data = list(set(data))\n",
    "\n",
    "len(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:07:57.284812Z",
     "start_time": "2024-03-11T10:07:57.282051Z"
    }
   },
   "id": "ee2538ed45cbc1a6"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 11\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# matplotlib.use(\"pgf\")\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# # matplotlib.rcParams.update({\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m#     # \"pgf.texsystem\": \"pdflatex\",\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m#     # 'pgf.rcfonts': False,\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# })\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m plt\u001B[38;5;241m.\u001B[39mhist([\u001B[38;5;28mlen\u001B[39m(d) \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdata\u001B[49m], bins\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC0\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     12\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLength of description\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     13\u001B[0m plt\u001B[38;5;241m.\u001B[39mylabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNumber of datasets\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use(\"pgf\")\n",
    "# # matplotlib.rcParams.update({\n",
    "#     # \"pgf.texsystem\": \"pdflatex\",\n",
    "#     'font.family': 'serif',\n",
    "#     # 'text.usetex': True,\n",
    "#     # 'pgf.rcfonts': False,\n",
    "# })\n",
    "\n",
    "plt.hist([len(d) for d in data], bins=100, color='C0')\n",
    "plt.xlabel('Length of description')\n",
    "plt.ylabel('Number of datasets')\n",
    "# set figure size to smaller\n",
    "plt.gcf().set_size_inches(4.65, 3)\n",
    "\n",
    "plt.subplots_adjust(left=0.15, bottom=0.15, right=0.95, top=0.95)\n",
    "# adjust just bottom, not top left or right\n",
    "# plt.subplots_adjust(bottom=0.15)\n",
    "\n",
    "# plt.show()\n",
    "# save fig as pdf\n",
    "# plt.savefig('description_length_histogram.pdf')\n",
    "\n",
    "# import tikzplotlib\n",
    "# tikzplotlib.save(\"description_length_histogram.tex\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:20:36.754320Z",
     "start_time": "2024-03-11T10:20:36.513826Z"
    }
   },
   "id": "958eb9c019b2ecc1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.get_num_threads())\n",
    "torch.set_num_threads(1)\n",
    "print(torch.get_num_threads())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:07:58.287559Z",
     "start_time": "2024-03-11T10:07:58.279039Z"
    }
   },
   "id": "feacfd2fe9ab444d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentence_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "embeddings = sentence_model.encode(data, show_progress_bar=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T10:07:58.280244Z"
    }
   },
   "id": "53cb5226a5a7b1cb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance\n",
    "\n",
    "# we add this to remove stopwords\n",
    "# vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
    "# vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "# model = BERTopic(vectorizer_model=vectorizer_model,\n",
    "#                  language=\"english\",\n",
    "#                  calculate_probabilities=True,\n",
    "#                  verbose=True)\n",
    "representation_model = KeyBERTInspired()\n",
    "# representation_model = MaximalMarginalRelevance(diversity=0.3)\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    verbose=True,\n",
    "    nr_topics=50,\n",
    "    calculate_probabilities=True,\n",
    "    embedding_model=sentence_model,\n",
    "    # vectorizer_model=vectorizer_model,\n",
    "    representation_model=representation_model\n",
    ")\n",
    "topics, probs = topic_model.fit_transform(data, embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T10:07:58.281594Z"
    }
   },
   "id": "6b4e0ed73a04049"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from bertopic import BERTopic\n",
    "# from ctransformers import AutoModelForCausalLM\n",
    "# from transformers import AutoTokenizer, pipeline\n",
    "# \n",
    "# # Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "# mistral_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     \"TheBloke/zephyr-7B-alpha-GGUF\",\n",
    "#     model_file=\"zephyr-7b-alpha.Q4_K_M.gguf\",\n",
    "#     model_type=\"mistral\",\n",
    "#     gpu_layers=50,\n",
    "#     hf=True\n",
    "# )\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-alpha\")\n",
    "# \n",
    "# # Pipeline\n",
    "# generator = pipeline(\n",
    "#     model=mistral_model, tokenizer=tokenizer,\n",
    "#     task='text-generation',\n",
    "#     max_new_tokens=50,\n",
    "#     repetition_penalty=1.1\n",
    "# )\n",
    "# \n",
    "# prompt = \"\"\"<|system|>You are a helpful, respectful and honest assistant for labeling topics..</s>\n",
    "# <|user|>\n",
    "# I have a topic that contains the following documents:\n",
    "# [DOCUMENTS]\n",
    "# \n",
    "# The topic is described by the following keywords: '[KEYWORDS]'.\n",
    "# \n",
    "# Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.</s>\n",
    "# <|assistant|>\"\"\"\n",
    "# \n",
    "# from bertopic.representation import TextGeneration\n",
    "# \n",
    "# # Text generation with Zephyr\n",
    "# zephyr = TextGeneration(generator, prompt=prompt)\n",
    "# representation_model = {\"Zephyr\": zephyr}\n",
    "# \n",
    "# # Topic Modeling\n",
    "# model = BERTopic(representation_model=representation_model, verbose=True)\n",
    "# topics, probs = model.fit_transform(dataset_descriptions, embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T10:07:58.283170Z"
    }
   },
   "id": "605bf44eaca2f032",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# from bertopic.representation import TextGeneration\n",
    "# \n",
    "# prompt = \"I have a topic described by the following keywords: [KEYWORDS]. Based on the previous keywords, what is this topic about?\"\n",
    "# \n",
    "# # Create your representation model\n",
    "# generator = pipeline('text2text-generation', model='google/flan-t5-base')\n",
    "# representation_model = TextGeneration(generator)\n",
    "# model = BERTopic(representation_model=representation_model, verbose=True)\n",
    "# topics, probs = model.fit_transform(dataset_descriptions, embeddings)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T10:07:58.284588Z"
    }
   },
   "id": "53ae6dd7cfdc6a4f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(f\"{topics[i]}: {len(data[i])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T10:07:58.285861Z"
    }
   },
   "id": "d9532c4e881014d1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "topic_model.get_document_info(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T10:07:58.287089Z"
    }
   },
   "id": "a7d591e37dc59f30",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "topic_model.generate_topic_labels()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:07:58.289684Z",
     "start_time": "2024-03-11T10:07:58.288328Z"
    }
   },
   "id": "69f3fe30378a7869",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:07:58.298095Z",
     "start_time": "2024-03-11T10:07:58.289754Z"
    }
   },
   "id": "605b91f1d69b409c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "topic_model.topic_sizes_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T10:07:58.291155Z"
    }
   },
   "id": "95bc40292bd67bfb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "topic_model.visualize_documents(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T10:07:58.292097Z"
    }
   },
   "id": "f2c6866b801cfaf2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T10:07:58.292823Z"
    }
   },
   "id": "a92e50cc977344e4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T10:07:58.293538Z"
    }
   },
   "id": "7c2da95c2d24bc8e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T10:07:58.294127Z"
    }
   },
   "id": "f6a3c41dbe657eda",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart(top_n_topics = 16, n_words=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T10:07:58.295469Z"
    }
   },
   "id": "c6d182e5f1d519c8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# plotly = topic_model.visualize_barchart(top_n_topics = 16, n_words=10)\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# now visualize only topic 0\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[43mtopic_model\u001B[49m\u001B[38;5;241m.\u001B[39mset_topic_labels({\u001B[38;5;241m2\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTopic 1\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m3\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTopic 2\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m4\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTopic 3\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m7\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTopic 4\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m9\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTopic 5\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m11\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTopic 6\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m12\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTopic 7\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m13\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTopic 8\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m14\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTopic 9\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m15\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTopic 10\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m0\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTopic 11\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTopic 12\u001B[39m\u001B[38;5;124m\"\u001B[39m})\n\u001B[1;32m      4\u001B[0m plotly \u001B[38;5;241m=\u001B[39m topic_model\u001B[38;5;241m.\u001B[39mvisualize_barchart(topics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m7\u001B[39m, \u001B[38;5;241m9\u001B[39m, \u001B[38;5;241m11\u001B[39m, \u001B[38;5;241m12\u001B[39m, \u001B[38;5;241m13\u001B[39m, \u001B[38;5;241m14\u001B[39m, \u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m], n_words\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, title\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m, custom_labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, height\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m270\u001B[39m)\n\u001B[1;32m      5\u001B[0m plotly\u001B[38;5;241m.\u001B[39mshow()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'topic_model' is not defined"
     ]
    }
   ],
   "source": [
    "# plotly = topic_model.visualize_barchart(top_n_topics = 16, n_words=10)\n",
    "# now visualize only topic 0\n",
    "topic_model.set_topic_labels({2: \"Topic 1\", 3: \"Topic 2\", 4: \"Topic 3\", 7: \"Topic 4\", 9: \"Topic 5\", 11: \"Topic 6\", 12: \"Topic 7\", 13: \"Topic 8\", 14: \"Topic 9\", 15: \"Topic 10\", 0: \"Topic 11\", 1: \"Topic 12\"})\n",
    "plotly = topic_model.visualize_barchart(topics=[2, 3, 4, 7, 9, 11, 12, 13, 14, 15, 0, 1], n_words=10, title=\"\", custom_labels=True, height=270)\n",
    "plotly.show()\n",
    "plotly.write_image(\"topics_barchart.pdf\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:18:00.516689Z",
     "start_time": "2024-03-11T10:18:00.423879Z"
    }
   },
   "id": "266f1fdc3983f62f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "topic_model.get_topic(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T10:07:58.303865Z",
     "start_time": "2024-03-11T10:07:58.299132Z"
    }
   },
   "id": "b477ebcdd6ce67ce",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(topic_model.get_representative_docs(12)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T10:07:58.300206Z"
    }
   },
   "id": "d13b2e470e9b85fb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get the pandas dataframe\n",
    "# topic_model.get_document_info(data)\n",
    "# print only where column Topic is -1\n",
    "topic_model.get_document_info(data)[topic_model.get_document_info(data)[\"Topic\"] == 12]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T10:07:58.300992Z"
    }
   },
   "id": "b515ab1318d1c50e",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
