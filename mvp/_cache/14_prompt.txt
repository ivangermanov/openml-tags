Based on the below information, extract and synthesize human-readable tags/keywords/themes from the text, capitalized first letters of words. What is the main human-readable theme or subject matter discussed in the provided texts? What is the overarching, high-level theme of the texts, e.g. "Music", "Sports", "Environment", etc.? Please provide overarching themes that tie the different pieces of information together. What is/are the overarching, highest level theme(s) that you could use as a keyword(s)? Prefer single word tags/keywords, e.g. "Tennis" rather than "Tennis Match", "Prison" rather than "Prison Time", etc., however, if the term makes sense only as a whole, e.g. "Republic of the Congo", "COVID-19", then use it! Consider adding synonyms as well, e.g. for "Influenza", add "Flu", for "Car", add "Automobile", etc.! Some examples of human-readable themes are   "Agriculture", "Astronomy", "Chemistry", "Computational Universe", "Computer Systems", "Climate and Environment", "Culture", "Demographics", "Earth Science", "Economics", "Education", "Engineering", "Finance", "Geography", "Government", "Games", "Health", "History", "Human Activities", "Images", "Language", "Law", "Life Science", "Machine Learning", "Manufacturing", "Mathematics", "Medicine", "Meteorology", "Physical Sciences", "Politics", "Social Media", "Sociology", "Statistics", "Text & Literature",  "Transportation". Avoid tags/keywords that are too specific, e.g. "Serine Threonine Protein Kinase". Good theme examples are: "Birds", "Species Migration", "Air Pollution", or "War", "Government", "International Relations", "Politics". And be concise in theme generation, e.g. instead of "Income Prediction", say "Income", instead of "Demographic Information", say "Demographics"! Another important rule to obey - place more focus on the dataset names for theme extraction, if they exist. Say {"topic": {"themes": ["example1", "example2", ...], "overarching_themes": ["example13", "...", ...]}, "texts": [{"example1": 0.93, "example2": 0.68, "...": ..., ..., "example13": ..., ... (strings corresponding to themes and overarching themes for text 1, all of them)}], {"example1": 0.87, "example2": 0.34, "...": ..., ..., "example13": ..., ... (strings corresponding to themes and overarching themes for text 2, all of them)}]} and give your answer in JSON format, where under "topic" you put all themes and overarching themes, and in "texts", you give a confidence score in each theme and overarching theme for each text. "themes" and "overarching_themes" shouldn't overlap. If a theme is overarching and common to all texts, it should be present in all texts with a high score. Give only the ones with highest scores.
For example, for this text:
ID: 506

Name: Biden Administration

The Biden administration is preparing to roll out a sweeping border executive action as early as Tuesday, according to two sources familiar with the discussions, who cautioned that timing is fluid.

White House officials have begun reaching out to mayors who represent cities along the US southern border to potentially join President Joe Biden when he announces the order, two other sources familiar with those conversations said.

For weeks, administration officials have been working through an executive action that would dramatically limit migrants’ ability to seek asylum at the US southern border — part of a strategy to try to give Biden the upper hand on one of his Republican rival’s key campaign issues. The action is designed to potentially blunt Republican attacks on border security and preempt former President Donald Trump ahead of the first presidential debate, which will be held on June 27 on CNN.
---
ID: 401

Name: Name: Trump conviction

Now that a New York jury has convicted former President Donald Trump of all 34 felony charges of falsifying business records, the next obvious question is: Can a convicted felon run for president?

Definitely.

Trump meets all three requirements. There is, arguably, another criterion laid out in the 14th Amendment, where it states that no one who has previously taken an oath of office who engages in insurrection can be an officer of the US. But the US Supreme Court ruled earlier this year that Congress would have to pass a special law invoking this prohibition. That’s not happening any time soon.

Judge Juan Merchan has scheduled Trump’s sentencing for July 11, which happens to be four days before the start of the Republican National Convention that is scheduled to take place in Milwaukee.

It is technically possible, although perhaps unlikely for a first-time offender, that Trump could be sentenced to prison time.
---
ID: 51376

Name: Trump has vowed to give green cards to college grads. Could that actually happen?

The candidate known for touting immigration crackdowns told a group of tech investors that he wanted to help foreign students stay in the US.

“What I want to do, and what I will do, is — you graduate from a college, I think you should get automatically, as part of your diploma, a green card to be able to stay in this country,” Trump said during a June interview with “The All-In Podcast.”

If the president-elect pursues this proposal after he takes office, and if Congress passes the legislation that would be required to enact it, the policy could pave the way for potentially millions of international students to become legal permanent residents.
---
This would be your answer:
{
  "topic": {
    "themes": [
      "Biden Administration",
      "Border",
      "Executive Action",
      "Asylum",
      "Immigration",
      "Trump",
      "Felony",
      "Business Records",
      "Presidential Campaign",
      "Republican",
      "Debate",
      "Former President",
      "Conviction",
      "Sentencing",
      "Prison",
      "14th Amendment",
      "Insurrection",
      "Supreme Court",
      "Republican National Convention",
      "College",
      "Green Card",
      "Legislation",
      "Student"
    ],
    "overarching_themes": [
      "Politics",
      "Government",
      "Law",
      "Justice",
      "Elections",
      "Education"
    ]
  },
  "texts": { 
    506: {
      "Biden Administration": 0.96,
      "Border": 0.92,
      "Executive Action": 0.91,
      "Asylum": 0.88,
      "Immigration": 0.84,
      "Presidential Campaign": 0.82,
      "Republican": 0.82,
      "Debate": 0.78,
      "Politics": 0.99,
      "Government": 0.93,
      "Law": 0.85,
      "Elections": 0.72,
    },
    401: {
      "Trump": 0.95,
      "Felony": 0.92,
      "Business Records": 0.97,
      "Presidential Campaign": 0.84,
      "Republican": 0.82,
      "Former President": 0.98,
      "Conviction": 0.92,
      "Sentencing": 0.91,
      "Prison": 0.85,
      "14th Amendment": 0.82,
      "Insurrection": 0.80,
      "Supreme Court": 0.78,
      "Republican National Convention": 0.76,
      "Politics": 0.92,
      "Government": 0.92,
      "Law": 0.90,
      "Justice": 0.88,
      "Elections": 0.85,
    },
    51376: {
      "Immigration": 0.67,
      "Trump": 0.98,
      "Republican": 0.59,
      "College": 0.98,
      "Green Card": 0.93,
      "Legislation": 0.89,
      "Student": 0.89,
      "Politics": 0.82,
      "Government": 0.81,
      "Law": 0.69,
      "Education": 0.97
    }
  }
}
---
Now, the above was just an example. Now, do it for all the following text(s), generate many themes, make sure to return for each dataset ID!:
- ID: 46310

Name: Tok-Pisin-English

Tags: 

Training data for ai

Features: prompt, completion
---
- ID: 45573

Name: HotpotQA_distractor

Tags: 

HotpotQA is a new dataset with 113k Wikipedia-based question-answer pairs with four key features: (1) the questions require finding and reasoning over multiple supporting documents to answer; (2) the questions are diverse and not constrained to any pre-existing knowledge bases or knowledge schemas; (3) we provide sentence-level supporting facts required for reasoning, allowingQA systems to reason with strong supervision and explain the predictions; (4) we offer a new type of factoid comparison questions to test QA systems' ability to extract relevant facts and perform necessary comparison. The dataset is taken from https://huggingface.co/datasets/hotpot_qa and this upload is the 'distractor' subset.

Features: id, question, answer, type, level, supporting_facts, context
---
- ID: 40590

Name: enron

Tags: 2016_multilabel_r_benchmark_paper

Multi-label dataset. The UC Berkeley enron4 dataset represents a subset of the original enron5 dataset and consists of 1684 cases of emails with 21 labels and 1001 predictor variables.

Features: X0, X00, X000, X01, X02, X03, X04, X05, X06, X07, X08, X09, X1, X10, X100, X11, X12, X13, X14, X15, X16, X17, X18, X19, X1999, X2, X20, X200, X2000, X2001, X2002, X20a, X20and, X20as, X20at, X20but, X20by, X20california, X20davis, X20edison, X20electricity, X20energy, X20for, X20from, X20in, X20it, X20of, X20on, X20pg, X20power, X20prices, X20said, X20state
---
- ID: 40596

Name: slashdot

Tags: 2016_multilabel_r_benchmark_paper

Multi-label dataset for text-classification. It consists of article titles and partial blurbs. Blurbs can be assigned to several categories (e.g. Science, News, Games) based on word predictors.

Features: Entertainment, Interviews, Main, Developers, Apache, News, Search, Mobile, Science, IT, BSD, Idle, Games, YourRightsOnline, AskSlashdot, Apple, BookReviews, Hardware, Meta, Linux, Politics, Technology, X0, X000, X1, X10, X100, X11, X12, X15, X1up, X2, X20, X2008, X2009, X24, X25, X26, X3, X30, X360, X3d, X3g, X4, X40, X5, X50, X500, X6, X7, X8, X9, access, account, act, action, active, activision, ad, add, added, addition, adobe, advanced, age, agency, ago, agreement, ai, air, allowing, alternative, amazon, amd
---
- ID: 43691

Name: Are-Two-Sentences-of-the-Same-Topic

Tags: 

Do two sentences come from the same article?  We randomly sampled sentences from across Wikipedia.  Some sentences came from the same articles, others do not.  
Sentences from the Same Article
These two sentences are from the same article.

There were 2,788 housing units at an average density of 4 per squaremile (2/km).    
It is also home to the Oklahoma State Reformatory, located in Granite.

So are these:

Monument of the Judiciary Citadel of Salerno, near the Colle Bellara.    
The La Carnale Castle got his name from a medieval battle against the Arabs and is part of a sport complex (with pool, tennis courts and hockey).

As are these:

The idea of Haar measure is to take a sort of limit of  as  becomes smaller to make it additive on all pairs of disjoint compact sets, though it first has to be normalized so that the limit is not just infinity.    
When left and right Haar measures differ, the right measure is usually preferred as a prior distribution.

Sentences from Different Articles
These two sentences are from different articles:

US Open womens doubles champion   
---
- ID: 41547

Name: reuters

Tags: 2019_multioutput_paper_benchmark_data

Multi-label dataset. A subset of the reuters dataset includes 2000
  observations for text classification.

Features: feature1, feature2, feature3, feature4, feature5, feature6, feature7, feature8, feature9, feature10, feature11, feature12, feature13, feature14, feature15, feature16, feature17, feature18, feature19, feature20, feature21, feature22, feature23, feature24, feature25, feature26, feature27, feature28, feature29, feature30, feature31, feature32, feature33, feature34, feature35, feature36, feature37, feature38, feature39, feature40, feature41, feature42, feature43, feature44, feature45, feature46, feature47, feature48, feature49, feature50, feature51, feature52, feature53, feature54, feature55, feature56, feature57, feature58, feature59, feature60, feature61, feature62, feature63, feature64, feature65, feature66, feature67, feature68, feature69, feature
---
- ID: 41470

Name: reuters

Tags: 2019_multioutput_paper

Multi-label dataset. A subset of the reuters dataset includes 2000
  observations for text classification.

Features: feature1, feature2, feature3, feature4, feature5, feature6, feature7, feature8, feature9, feature10, feature11, feature12, feature13, feature14, feature15, feature16, feature17, feature18, feature19, feature20, feature21, feature22, feature23, feature24, feature25, feature26, feature27, feature28, feature29, feature30, feature31, feature32, feature33, feature34, feature35, feature36, feature37, feature38, feature39, feature40, feature41, feature42, feature43, feature44, feature45, feature46, feature47, feature48, feature49, feature50, feature51, feature52, feature53, feature54, feature55, feature56, feature57, feature58, feature59, feature60, feature61, feature62, feature63, feature64, feature65, feature66, feature67, feature68, feature69, feature70, feature
---
- ID: 41466

Name: enron

Tags: 2019_multioutput_paper

Multi-label dataset. The UC Berkeley enron4 dataset represents a
  subset of the original enron5 dataset and consists of 1684 cases of emails
  with 21 labels and 1001 predictor variables.

Features: X0, X00, X000, X01, X02, X03, X04, X05, X06, X07, X08, X09, X1, X10, X100, X11, X12, X13, X14, X15, X16, X17, X18, X19, X1999, X2, X20, X200, X2000, X2001, X2002, X20a, X20and, X20as, X20at, X20but, X20by, X20california, X20davis, X20edison, X20electricity, X20energy, X20for, X20from, X20in, X20it, X20of, X20on, X20pg, X20power, X20prices, X20said, X20state
---
- ID: 40593

Name: langLog

Tags: 2016_multilabel_r_benchmark_paper

The langLog dataset includes 1004 textual predictors and was originally compiled in the doctorial thesis of Read (2010). It consists of 956 text samples that can be assigned to one or more topics such as language, politics, errors, humor and computational linguistics. Note that the data on OpenML uses modified names for taget labels which were longer than 18 characters.

Features: Errors, Humor, SpeechActs, PrescrptvstPppycck, PhoneticsAndPhnlgy, Punctuation, Administration, LanguageAndCulture, ThisBloggingLife, IgnoranceOfLngstcs, HLT, Announcements, Syntax, coordination, LanguageAndTheMedi, Uncategorized, AnimalCommunicatin, Linguification, LanguagAndAdvrtsng, Quizzes, Snowclones, Fieldwork, negation, Variation, LanguageAndSports, prepositions, Obituaries, LanguagePlanning, whoWhom, WTF, Discrimination, LanggTchngAndLrnng, LinguistcsInThCmcs, Ethics, LanguageInTheMovis, TheAcademicScene, Pragmatics, Sem
---
- ID: 41899

Name: MultilingualDS

Tags: 

Data set of around 45 language and 25 Category. Consist of articles.

Features: Label, Language, Text
---
- ID: 40594

Name: reuters

Tags: 2016_multilabel_r_benchmark_paper, multi_label

Multi-label dataset. A subset of the reuters dataset includes 2000 observations for text classification.

Features: feature1, feature2, feature3, feature4, feature5, feature6, feature7, feature8, feature9, feature10, feature11, feature12, feature13, feature14, feature15, feature16, feature17, feature18, feature19, feature20, feature21, feature22, feature23, feature24, feature25, feature26, feature27, feature28, feature29, feature30, feature31, feature32, feature33, feature34, feature35, feature36, feature37, feature38, feature39, feature40, feature41, feature42, feature43, feature44, feature45, feature46, feature47, feature48, feature49, feature50, feature51, feature52, feature53, feature54, feature55, feature56, feature57, feature58, feature59, feature60, feature61, feature62, feature63, feature64, feature65, feature66, feature67, feature68, feature69
---
- ID: 41469

Name: langLog

Tags: 2019_multioutput_paper

The langLog dataset includes 1004 textual predictors and was
  originally compiled in the doctorial thesis of Read (2010). It consists of 956
  text samples that can be assigned to one or more topics such as language,
  politics, errors, humor and computational linguistics.
  Note that the data on OpenML uses modified names for taget labels which were
  longer than 18 characters.

Features: Errors, Humor, SpeechActs, PrescrptvstPppycck, PhoneticsAndPhnlgy, Punctuation, Administration, LanguageAndCulture, ThisBloggingLife, IgnoranceOfLngstcs, HLT, Announcements, Syntax, coordination, LanguageAndTheMedi, Uncategorized, AnimalCommunicatin, Linguification, LanguagAndAdvrtsng, Quizzes, Snowclones, Fieldwork, negation, Variation, LanguageAndSports, prepositions, Obituaries, LanguagePlanning, whoWhom, WTF, Discrimination, LanggTchngAndLrnng, LinguistcsInThCmcs, Ethics, LanguageInTheMovis, TheAcademicScene,
---
- ID: 41472

Name: slashdot

Tags: 2019_multioutput_paper

Multi-label dataset for text-classification. It consists of
  article titles and partial blurbs. Blurbs can be assigned to several
  categories (e.g. Science, News, Games) based on word predictors.

Features: Entertainment, Interviews, Main, Developers, Apache, News, Search, Mobile, Science, IT, BSD, Idle, Games, YourRightsOnline, AskSlashdot, Apple, BookReviews, Hardware, Meta, Linux, Politics, Technology, X0, X000, X1, X10, X100, X11, X12, X15, X1up, X2, X20, X2008, X2009, X24, X25, X26, X3, X30, X360, X3d, X3g, X4, X40, X5, X50, X500, X6, X7, X8, X9, access, account, act, action, active, activision, ad, add, added, addition, adobe, advanced, age, agency, ago, agreement, ai, air, allowing, alternative, amazon, amd
---

The topic is described by the following keywords: multilabel, reuters, sentences, langlog, x500, humor, x000, x3d, blurbs, 1001, politics, x100, 2016multilabelrbenchmarkpaper, agreement, x0, x50, administration, x40, act, feature83, feature79, feature82, feature80, feature77, feature87, feature78, feature84, feature85, feature86, feature81
---
Remember, generate many themes and overarching themes, each one should be used in the classifications (don't skip any of the generated themes and overarching themes), then classify each dataset id by them, make sure to return for each dataset ID - 46310, 45573, 40590, 40596, 43691, 41547, 41470, 41466, 40593, 41899, 40594, 41469, 41472 !
