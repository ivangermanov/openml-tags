\chapter{Recommendations}
\label{chapter:recommendations}
In this chapter, we present several key recommendations for improving and extending the tag generation system, ranging from immediate practical enhancements to longer-term research directions.

\section{Pipeline component updates}
The modular nature of our pipeline presents ongoing opportunities for improvement through the integration of newer, better-performing submodels. The rapid advancement in language models and embedding techniques means that regularly evaluating and incorporating new submodels could yield improvements. Particularly promising areas include embedding models achieving high scores on the MTEB benchmark \cite{muennighoff_mteb_2023}, newer LLMs for fine-tuning, and improved zeroshot text classifiers. Our automated evaluation pipeline and large-scale automated evaluation methodology allow for quick testing of these components, making continuous improvement practical and efficient.

\section{Improved zeroshot classification} 
While the current zeroshot text classifier performs adequately, there is potential for improvement in this area. Training a custom zeroshot model with a better base architecture could be an entire Master's project in itself, given the complexity and resource requirements involved. The zeroshot text classifier in this thesis is based on DeBERTa \cite{he_deberta_2021}, a relatively small and old model.

A more practical short-term solution would be to use a pre-trained LLM for zeroshot text classification. Dedicated zeroshot models are usually smaller and trained less frequently because they are highly specialized for one task. As a result, there is less demand for them compared to general-purpose LLMs, which tend to perform better across a wider range of tasks, including text classification (for our experiments demonstrating this, refer to the \textit{preliminary\_model.ipynb} notebook in the \href{https://github.com/ivangermanov/openml-tags}{GitHub repository} \cite{germanov_topic_modeling_of_2024}). Even though the LLM would not provide confidence scores, it would still likely outperform the current zeroshot model. For long-term development, following \citet{laurer_building_2024}'s work on training zeroshot text classifiers could provide a valuable starting point for training a custom model.

\section{External dataset validation}
To validate the broader applicability of our approach, we recommend conducting word intruder tests on popular datasets beyond OpenML. This evaluation would help assess the model's generalizability and identify potential areas for improvement when handling different types of data. Furthermore, comparing results against current state-of-the-art topic models would provide valuable insights into the strengths and limitations of our approach. To start this process, we recommend finding the relevant literature in which word intruder tests are used to evaluate topic models and adapting these methods to our context \cite{chang_reading_2009,lau_machine_2014,hoyle_is_2021,newman_evaluating_2010,mimno_optimizing_nodate,musil_exploring_2024,bhatia_automatic_2017}.

\section{OpenML platform integration}
For the OpenML platform, we recommend keeping track of which tags are generated by the model and which are human-generated. This would allow for easy updates to the tags in the future when the entire model is rerun, without affecting the human-generated tags.

\section{Online topic modeling}
We recommend exploring iterative (online) dimensionality reduction and, especially, clustering algorithms to address the limitations of the current static approaches. To take the example of clustering, hierarchical clustering algorithms such as HDBSCAN have been shown to be effective in many applications \cite{campello_density-based_2013, mcinnes_accelerated_2017, mcinnes_hdbscan_2017}, but they are static. Static clustering has limitations in that they are run once for a fixed set of data and do not adapt to size changes in the dataset.

Recalculating the clustering from scratch for each new dataset is not computationally expensive for our dataset of approximately 5000 descriptions, but could become an issue as the dataset grows. For instance, HDBSCAN's time complexity is $O(n^2)$ for computing the distance matrix, which could become a bottleneck for larger datasets. Iterative clustering algorithms, on the other hand, can adapt to changes in the dataset without having to recalculate the clusters from scratch.

Researching and implementing iterative dimensionality reduction algorithms such as Incremental PCA \cite{balsubramani_fast_2013,artac_incremental_2002,dagher_incremental_2010}, and iterative clustering algorithms \cite{montiel_online_2022} such as Mini Batch K-means \cite{bejar_alonso_k-means_2013,hicks_mbkmeans_2021} or BIRCH \cite{zhang_birch_1996} could provide a more scalable and efficient solution for the long-term.