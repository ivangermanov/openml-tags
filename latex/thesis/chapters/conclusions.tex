Write your conclusions here.

maybe split recommendations into separate small chapter

\section{Recommendations}
1. Keep looking for improved submodels — embedding model and fine-tuning model and zeroshot model especially. These models can be tested with the automated evaluation metrics and with the GPT evaluation quickly, quick iterations.

2. Look into training a custom zeroshot model with a better base architecture — this could be a separate Master's project on its own. Look into Moritz Laurer's work on zeroshot learning. Or, more realistically, use a pre-trained LLM to do zeroshot classification. It will not return scores, but it will still perform better than zeroshot text classification models, as zeroshot models are not trained very frequently, and are small.

3. Additionally, word intruder tests could be used to evaluate whether the proposed model performs better on popular datasets than the current state of the art. This could be a good way to evaluate the model's generalizability.

4. Keep track of which tags are created by the model and which are human-created. This would let you easily update the tags in the future, when the whole model is rerun.