\chapter*{Abstract}\label{chapter:abstract}

This thesis presents a novel approach to automatically generate tags for OpenML dataset descriptions using topic modeling techniques. Effective dataset tagging is important for organizing datasets on the OpenML platform \cite{vanschoren_openml_2014}, improving their discoverability, and enabling users to quickly identify relevant datasets for their needs. While OpenML datasets are currently categorized using both manual tagging and a semantic tagging approach that uses \textit{GPT-3.5-turbo} to automatically assign predefined tags based on dataset descriptions, many datasets still lack semantic tags that are sufficiently informative and readable by humans. The current semantic tagging approach also has limitations as it does not leverage additional metadata beyond the dataset descriptions.

We develop a modular pipeline that extends the BERTopic model \cite{grootendorst_bertopic_2022} with advanced language models and zeroshot text classification to automatically generate high-quality, human-readable tags. Through an exploratory data analysis, we first investigate OpenML dataset descriptions and augment them with additional metadata and contextual information. We then develop our pipeline, which combines state-of-the-art embedding models, specifically the \textit{Salesforce/SFR-Embedding-2\_R} \cite{noauthor_salesforcesfr-embedding-2_r_2024} model found on the MTEB Benchmark \cite{muennighoff_mteb_2023}, UMAP for dimensionality reduction \cite{mcinnes_umap_2020}, HDBSCAN for clustering \cite{campello_density-based_2013, mcinnes_accelerated_2017, mcinnes_hdbscan_2017}, and fine-tuning with a large language model, \textit{Llama-3-70b} \cite{noauthor_introducing_nodate} , combined with zeroshot text classification using the \textit{MoritzLaurer/deberta-v3-large-zeroshot-v2.0} model \cite{noauthor_milanlproccontextualized-topic-models_2024}. The modular nature of our approach ensures it can evolve alongside advances in language models and embedding models. We also explore a cost-effective configuration that simplifies the pipeline and utilizes a smaller LLM (GPT-4o-mini \cite{noauthor_gpt-4o_nodate}).

We evaluate our model using both automated metrics and human evaluation. Our automated evaluation reveals that the proposed model achieves a combined NPMI and diversity score of 0.779, outperforming all baseline models, including LDA \cite{blei_latent_2001}, NMF \cite{shahnaz_document_2006, kasiviswanathan_emerging_2011, yan_learning_2013}, Top2Vec \cite{angelov_top2vec_2020}, and CTM \cite{bianchi_pre-training_2021, bianchi_cross-lingual_2021} on this metric, while achieving the highest diversity score of 0.808. A human evaluation study with 21 participants demonstrates that our model generates tags that are more relevant (mean score of 3.63) and provide better coverage (mean score of 4.46) compared to the baseline approach (2.39 and 2.65 respectively), while maintaining a good balance between specific and general tags (SD 1.40). In an intruder detection task, our model achieved a 95.2\% success rate, compared to 42.1\% for the baseline, and 100\% for human-generated tags. These findings are further validated through a large-scale automated evaluation using \textit{GPT-4-mini} across the entire OpenML dataset, where the LLM successfully identified 88.3\% of the intruders and rating the tags for relevance (mean 4.11, SD 0.98), generality (mean 3.29, SD 0.87), and coverage (mean 3.72).

Our approach provides OpenML with an automated, scalable solution for dataset tagging that produces high-quality tags approaching human-level performance. To the best of our knowledge, this is the first approach to combine a modular topic modeling pipeline like BERTopic with advanced techniques such as prompt-based fine-tuning with LLMs and zeroshot classification for automated dataset tagging. The techniques we developed could be applied to similar problems in other domains where automated categorization of content is needed. While this work demonstrates significant improvements in automated dataset tagging, we also acknowledge the limitations of using LLMs, particularly regarding computational cost and potential biases. Our method of combining traditional topic modeling with modern language models and zeroshot text classification represents a novel contribution to the field of topic modeling itself.

\textbf{Keywords}: topic modeling, machine learning, natural language processing, dataset tagging, OpenML, BERTopic